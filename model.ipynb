{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_1 = pd.read_csv('updated_ev_data.csv')\n",
    "data_2 = pd.read_csv('processed_ev_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16501 entries, 0 to 16500\n",
      "Data columns (total 8 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Vehicle ID              16501 non-null  object \n",
      " 1   Charger ID              16501 non-null  object \n",
      " 2   Date                    16501 non-null  object \n",
      " 3   Charging Time           16501 non-null  float64\n",
      " 4   Average Power           16501 non-null  float64\n",
      " 5   Max Power               13208 non-null  float64\n",
      " 6   Total Energy Delivered  16501 non-null  float64\n",
      " 7   SOC Charged             16501 non-null  float64\n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 1.0+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13909 entries, 0 to 13908\n",
      "Data columns (total 8 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Vehicle ID              13909 non-null  object \n",
      " 1   Charger ID              13909 non-null  object \n",
      " 2   Date                    13909 non-null  object \n",
      " 3   Charging Time           13752 non-null  float64\n",
      " 4   Average Power           13909 non-null  float64\n",
      " 5   Max Power               13152 non-null  float64\n",
      " 6   Total Energy Delivered  13909 non-null  float64\n",
      " 7   SOC Charged             13909 non-null  float64\n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 869.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data_1.info()\n",
    "data_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_process = data_2.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_raw = data_1[['Charging Time', 'Average Power', 'SOC Charged']]\n",
    "input_process = data_process[['Charging Time', 'Average Power', 'SOC Charged']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "scaler = StandardScaler()\n",
    "X_raw = scaler.fit_transform(input_raw)\n",
    "y_raw = data_1['Total Energy Delivered']\n",
    "X_process = scaler.fit_transform(input_process)\n",
    "y_process = data_process['Total Energy Delivered']\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X_raw, y_raw, test_size=0.2, random_state=42)\n",
    "X_train_process, X_test_process, y_train_process, y_test_process = train_test_split(X_process, y_process, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model Evaluation:\n",
      "Mean Squared Error (MSE): 1140.7464251434499\n",
      "R-squared (R2 Score): 0.7782404246698993\n"
     ]
    }
   ],
   "source": [
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_raw, y_train_raw)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = linear_model.predict(X_test_raw)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test_raw, y_pred)\n",
    "r2 = r2_score(y_test_raw, y_pred)\n",
    "\n",
    "print(\"Linear Regression Model Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2 Score): {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model Evaluation:\n",
      "Mean Squared Error (MSE): 0.38710956811392044\n",
      "R-squared (R2 Score): 0.6671751934500536\n"
     ]
    }
   ],
   "source": [
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_process, y_train_process)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = linear_model.predict(X_test_process)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test_process, y_pred)\n",
    "r2 = r2_score(y_test_process, y_pred)\n",
    "\n",
    "print(\"Linear Regression Model Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2 Score): {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Model Evaluation:\n",
      "Mean Squared Error (MSE): 1140.7513298427436\n",
      "R-squared (R2 Score): 0.7782394712029337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train_raw, y_train_raw)\n",
    "\n",
    "y_pred_ridge = ridge_model.predict(X_test_raw)\n",
    "\n",
    "mse_ridge = mean_squared_error(y_test_raw, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test_raw, y_pred_ridge)\n",
    "\n",
    "\n",
    "print(\"Ridge Regression Model Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_ridge}\")\n",
    "print(f\"R-squared (R2 Score): {r2_ridge}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Model Evaluation:\n",
      "Mean Squared Error (MSE): 0.38711898580025567\n",
      "R-squared (R2 Score): 0.667167096415284\n"
     ]
    }
   ],
   "source": [
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train_process, y_train_process)\n",
    "\n",
    "y_pred_ridge = ridge_model.predict(X_test_process)\n",
    "\n",
    "mse_ridge = mean_squared_error(y_test_process, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test_process, y_pred_ridge)\n",
    "\n",
    "\n",
    "print(\"Ridge Regression Model Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_ridge}\")\n",
    "print(f\"R-squared (R2 Score): {r2_ridge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Model Evaluation:\n",
      "Mean Squared Error (MSE): 1140.3176051269807\n",
      "R-squared (R2 Score): 0.778323786706062\n"
     ]
    }
   ],
   "source": [
    "lasso_model = Lasso(alpha=0.1)\n",
    "lasso_model.fit(X_train_raw, y_train_raw)\n",
    "y_pred_lasso = lasso_model.predict(X_test_raw)\n",
    "\n",
    "mse_lasso = mean_squared_error(y_test_raw, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_test_raw, y_pred_lasso)\n",
    "\n",
    "print(\"Lasso Regression Model Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_lasso}\")\n",
    "print(f\"R-squared (R2 Score): {r2_lasso}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Model Evaluation:\n",
      "Mean Squared Error (MSE): 0.45476246183146146\n",
      "R-squared (R2 Score): 0.6090093326220971\n"
     ]
    }
   ],
   "source": [
    "lasso_model = Lasso(alpha=0.1)\n",
    "lasso_model.fit(X_train_process, y_train_process)\n",
    "y_pred_lasso = lasso_model.predict(X_test_process)\n",
    "\n",
    "mse_lasso = mean_squared_error(y_test_process, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_test_process, y_pred_lasso)\n",
    "\n",
    "print(\"Lasso Regression Model Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_lasso}\")\n",
    "print(f\"R-squared (R2 Score): {r2_lasso}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Model Evaluation:\n",
      "Mean Squared Error (MSE): 20.140960919878218\n",
      "R-squared (R2 Score): 0.9960846242057951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_raw, y_train_raw)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test_raw)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test_raw, y_pred_rf)\n",
    "r2_rf = r2_score(y_test_raw, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest Regressor Model Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_rf}\")\n",
    "print(f\"R-squared (R2 Score): {r2_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Model Evaluation:\n",
      "Mean Squared Error (MSE): 0.04225931099346989\n",
      "R-squared (R2 Score): 0.9636667544156476\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_process, y_train_process)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test_process)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test_process, y_pred_rf)\n",
    "r2_rf = r2_score(y_test_process, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest Regressor Model Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_rf}\")\n",
    "print(f\"R-squared (R2 Score): {r2_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor Model Evaluation:\n",
      "Mean Squared Error (MSE): 50.53392565576374\n",
      "R-squared (R2 Score): 0.9901762726174874\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model.fit(X_train_raw, y_train_raw)\n",
    "\n",
    "y_pred_gb = gb_model.predict(X_test_raw)\n",
    "\n",
    "mse_gb = mean_squared_error(y_test_raw, y_pred_gb)\n",
    "r2_gb = r2_score(y_test_raw, y_pred_gb)\n",
    "\n",
    "print(\"Gradient Boosting Regressor Model Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_gb}\")\n",
    "print(f\"R-squared (R2 Score): {r2_gb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor Model Evaluation:\n",
      "Mean Squared Error (MSE): 0.06305034413686693\n",
      "R-squared (R2 Score): 0.9457912686258253\n"
     ]
    }
   ],
   "source": [
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model.fit(X_train_process, y_train_process)\n",
    "\n",
    "y_pred_gb = gb_model.predict(X_test_process)\n",
    "\n",
    "mse_gb = mean_squared_error(y_test_process, y_pred_gb)\n",
    "r2_gb = r2_score(y_test_process, y_pred_gb)\n",
    "\n",
    "print(\"Gradient Boosting Regressor Model Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_gb}\")\n",
    "print(f\"R-squared (R2 Score): {r2_gb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DAT\\AppData\\Local\\Temp\\ipykernel_19048\\2054442680.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_process[['Charging Time', 'Average Power', 'SOC Charged']] = scaler.fit_transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.4975\n",
      "Epoch [200/1000], Loss: 0.3571\n",
      "Epoch [300/1000], Loss: 0.3220\n",
      "Epoch [400/1000], Loss: 0.3020\n",
      "Epoch [500/1000], Loss: 0.2796\n",
      "Epoch [600/1000], Loss: 0.2578\n",
      "Epoch [700/1000], Loss: 0.2404\n",
      "Epoch [800/1000], Loss: 0.2292\n",
      "Epoch [900/1000], Loss: 0.2099\n",
      "Epoch [1000/1000], Loss: 0.2019\n",
      "Neural Network Model Evaluation:\n",
      "Mean Squared Error (MSE): 0.08364870399236679\n",
      "R-squared (R2 Score): 0.9222753047943115\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "data_process[['Charging Time', 'Average Power', 'SOC Charged']] = scaler.fit_transform(\n",
    "    data_process[['Charging Time', 'Average Power', 'SOC Charged']]\n",
    ")\n",
    "\n",
    "X_raw = data_process[['Charging Time', 'Average Power', 'SOC Charged']].values\n",
    "y_raw = data_process['Total Energy Delivered'].values\n",
    "\n",
    "X = torch.tensor(X_raw, dtype=torch.float32)\n",
    "y = torch.tensor(y_raw, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "train_size = int(0.8 * len(X))\n",
    "test_size = len(X) - train_size\n",
    "X_train, X_test = torch.utils.data.random_split(X, [train_size, test_size])\n",
    "y_train, y_test = torch.utils.data.random_split(y, [train_size, test_size])\n",
    "\n",
    "class EnergyDNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(EnergyDNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "input_size = X.shape[1]\n",
    "model = EnergyDNN(input_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_train.dataset)\n",
    "    loss = criterion(y_pred, y_train.dataset)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "model.eval()\n",
    "y_pred = model(X_test.dataset).detach().numpy()\n",
    "mse = mean_squared_error(y_test.dataset, y_pred)\n",
    "r2 = r2_score(y_test.dataset, y_pred)\n",
    "\n",
    "print(\"Neural Network Model Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2 Score): {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 6909.4980\n",
      "Epoch [200/1000], Loss: 5562.2734\n",
      "Epoch [300/1000], Loss: 3685.5007\n",
      "Epoch [400/1000], Loss: 2110.4395\n",
      "Epoch [500/1000], Loss: 1039.0194\n",
      "Epoch [600/1000], Loss: 463.1818\n",
      "Epoch [700/1000], Loss: 224.8819\n",
      "Epoch [800/1000], Loss: 156.7375\n",
      "Epoch [900/1000], Loss: 137.5736\n",
      "Epoch [1000/1000], Loss: 132.0477\n",
      "Neural Network Model Evaluation:\n",
      "Mean Squared Error (MSE): 27.71017074584961\n",
      "R-squared (R2 Score): 0.9949913024902344\n"
     ]
    }
   ],
   "source": [
    "data_1[['Charging Time', 'Average Power', 'SOC Charged']] = scaler.fit_transform(\n",
    "    data_1[['Charging Time', 'Average Power', 'SOC Charged']]\n",
    ")\n",
    "\n",
    "X_raw = data_1[['Charging Time', 'Average Power', 'SOC Charged']].values\n",
    "y_raw = data_1['Total Energy Delivered'].values\n",
    "\n",
    "X = torch.tensor(X_raw, dtype=torch.float32)\n",
    "y = torch.tensor(y_raw, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "train_size = int(0.8 * len(X))\n",
    "test_size = len(X) - train_size\n",
    "X_train, X_test = torch.utils.data.random_split(X, [train_size, test_size])\n",
    "y_train, y_test = torch.utils.data.random_split(y, [train_size, test_size])\n",
    "\n",
    "input_size = X.shape[1]\n",
    "model_2 = EnergyDNN(input_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_2.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    model_2.train()\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model_2(X_train.dataset)\n",
    "    loss = criterion(y_pred, y_train.dataset)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "model_2.eval()\n",
    "y_pred = model_2(X_test.dataset).detach().numpy()\n",
    "mse = mean_squared_error(y_test.dataset, y_pred)\n",
    "r2 = r2_score(y_test.dataset, y_pred)\n",
    "\n",
    "print(\"Neural Network Model Evaluation:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2 Score): {r2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
